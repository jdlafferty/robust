% !TEX root = ./robust.tex

\section{Experiments}
\label{sec:experiments}

In this section we discuss experimental results that illustrate and confirm the theoretical behavior of
median regression with corrupted data. In particular, we examine the scaling behavior of the error
with respect the level of corruption as the sample size, dimension, and correlation between predictor variables
are varied.



\subsection{Reduction of the robust lasso to median regression}

We first observe how the robust lasso is equivalent to median regression for transformed data. The robust lasso is the  estimator
\begin{align*}
  \hat\beta = \argmin_\beta \left\{ \frac{1}{n}\|y - X\beta\|_1 + \lambda \|\beta\|_1\right\}.
\end{align*}
The estimator can be rewritten as
\begin{align*}
  \hat\beta &= \argmin_\beta \left\{ \frac{1}{n}\|y - X\beta\|_1 + \lambda \|\beta\|_1 \right\} \\
  &= \argmin_\beta \left\{ \|y - X\beta\|_1 + \lambda n \|\beta\|_1 \right\} \\
  &= \argmin_\beta \|\tilde y - \tilde X_\lambda \beta\|_1
\end{align*}
where $\tilde y^T = (y^T, 0_p^T)$  and $\tilde X_\lambda^T = (X^T, \lambda n I_p)$.
We take $\lambda n = c\sqrt{n \log (2p)}$ for some constant $c$.

Using this reduction, we can carry out the estimation by
median regression of $\tilde y$ on $\tilde X_\lambda$. In all of our experiments below, the \texttt{quantreg} package in $R$ is used to carry out quantile regression for quantile level $\tau = \frac{1}{2}$. We do not tune the constant $c$, simply taking $c=0.5$.

Figure 1 shows two examples that illustrate the robustness of median regression
in the case of a single predictor variable. Here the noise $P_i$ is heteroskedastic, and 75\% of the response values are corrupted. Nonetheless, the estimated slope is very close to the true parameter. We can gain some intuition for this by observing that since the corrupting noise is independent of the predictor variable, the outliers are ``parallel'' to the regression function. 

\begin{figure*}[t]
  \begin{tabular}{cc}
    \hskip-3pt
    \includegraphics[width=.48\textwidth]{figures/fig1a} &
    \hskip-3pt
    \includegraphics[width=.48\textwidth]{figures/fig1b}\\[-5pt]
  \end{tabular}
\caption{Median regression for corrupted data with $n=1{,}000$ and $\epsilon=0.75$.
The baseline noise is heteroskedastic, with distribution $P_i = N(0, (1.5 x_i + 4)^2)$
for data point $x_i$. Left: Corrupting distributions
$Q_i = N(10, 1)$. Right: Corrupting distributions $Q_i = N(10 \cdot W_i, 1)$ where $W_i$ are
independent Rademacher random variables. The solid line is the true regression
function, and the dashed line is the fit using median regression.}
\label{fig:exp}
\vskip20pt
  \begin{center}
    \begin{tabular}{cc}
      \hskip-10pt
      \includegraphics[width=.48\textwidth]{figures/fig2a}&
      \includegraphics[width=.48\textwidth]{figures/fig2b}\\[-5pt]
    \end{tabular}
  \end{center}
\caption{Robust lasso for the linear model  $y=X\beta + z$ with design points $X_{ij}\sim N(0,1)$.
Left: Dimension $p$ varying as $p_{j} = e^{\rho^j}$, rounded down to the nearest integer, with $\rho=1.2$; the sample size is fixed at $n=100$, and $s=2$. Right: Dimension fixed at $p=10$ with $s=5$ relevant variables; the sample size $n$ is varied according to
$n_j = 2^j \cdot 20$ for $j=0,\ldots, 9$. The vertical axis shows the squared error $\|\hat \beta - \beta^*\|^2$ averaged over multiple trials.}
\end{figure*}
